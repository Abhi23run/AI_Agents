{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key = os.getenv('GROQ_API_KEY'))\n",
    "# MODEL = 'llama3-70b-8192'\n",
    "MODEL= 'llama-3.3-70b-versatile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=MODEL, \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "average_dog_weight:\n",
    "e.g. average_dog_weight: Collie\n",
    "returns average weight of a dog when given the breed\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: How much does a Bulldog weigh?\n",
    "Thought: I should look the dogs weight using average_dog_weight\n",
    "Action: average_dog_weight: Bulldog\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: A Bulldog weights 51 lbs\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: A bulldog weights 51 lbs\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(what):\n",
    "    return eval(what)\n",
    "\n",
    "def average_dog_weight(name):\n",
    "    if name in \"Scottish Terrier\": \n",
    "        return(\"Scottish Terriers average 20 lbs\")\n",
    "    elif name in \"Border Collie\":\n",
    "        return(\"a Border Collies average weight is 37 lbs\")\n",
    "    elif name in \"Toy Poodle\":\n",
    "        return(\"a toy poodles average weight is 7 lbs\")\n",
    "    else:\n",
    "        return(\"An average dog weights 50 lbs\")\n",
    "\n",
    "known_actions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_dog_weight\": average_dog_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up the dog's weight using average_dog_weight\n",
      "Action: average_dog_weight: Toy Poodle\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = abot(\"How much does a toy poodle weigh?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a toy poodles average weight is 7 lbs'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = average_dog_weight(\"Toy Poodle\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: A toy poodle weighs 7 lbs.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\naverage_dog_weight:\\ne.g. average_dog_weight: Collie\\nreturns average weight of a dog when given the breed\\n\\nExample session:\\n\\nQuestion: How much does a Bulldog weigh?\\nThought: I should look the dogs weight using average_dog_weight\\nAction: average_dog_weight: Bulldog\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: A Bulldog weights 51 lbs\\n\\nYou then output:\\n\\nAnswer: A bulldog weights 51 lbs'},\n",
       " {'role': 'user', 'content': 'How much does a toy poodle weigh?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Thought: I should look up the dog's weight using average_dog_weight\\nAction: average_dog_weight: Toy Poodle\\nPAUSE\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Observation: a toy poodles average weight is 7 lbs'},\n",
       " {'role': 'assistant', 'content': 'Answer: A toy poodle weighs 7 lbs.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all of this in unified function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_re = re.compile('^Action: (\\w+): (.*)$')   # python regular expression to selection action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a) \n",
    "            for a in result.split('\\n') \n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            # There is an action to run\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To find the combined weight of the two dogs, I need to find the average weight of a Border Collie and a Scottish Terrier. I can use the average_dog_weight action to get the weights of each breed and then add them together.\n",
      "\n",
      "Action: average_dog_weight: Border Collie\n",
      "PAUSE\n",
      " -- running average_dog_weight Border Collie\n",
      "Observation: a Border Collies average weight is 37 lbs\n",
      "Thought: Now that I have the average weight of a Border Collie, I need to find the average weight of a Scottish Terrier. I can use the average_dog_weight action again to get the weight of a Scottish Terrier.\n",
      "\n",
      "Action: average_dog_weight: Scottish Terrier\n",
      "PAUSE\n",
      " -- running average_dog_weight Scottish Terrier\n",
      "Observation: Scottish Terriers average 20 lbs\n",
      "Thought: Now that I have the average weights of both breeds, I can add them together to find the combined weight of the two dogs.\n",
      "\n",
      "Action: calculate: 37 + 20\n",
      "PAUSE\n",
      " -- running calculate 37 + 20\n",
      "Observation: 57\n",
      "Thought: The calculation is complete, and I have the combined weight of the two dogs.\n",
      "\n",
      "Answer: The combined weight of the Border Collie and the Scottish Terrier is 57 lbs.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Langgraph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=2) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=MODEL,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
    "abot = Agent(llm, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather today'}, 'id': 'call_ffy0', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in San Francisco is partly cloudy with a temperature of 53.1Â°F (11.7Â°C) and a feels-like temperature of 49.5Â°F (9.7Â°C). The wind is blowing at 11.0 mph (17.6 kph) from the northwest, and the humidity is 86%.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Super Bowl 2021 winner'}, 'id': 'call_0s2t', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Tampa Bay Buccaneers headquarters location'}, 'id': 'call_kqzp', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'GDP of Florida'}, 'id': 'call_avhe', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "# From the results, it looks like all the tool calls were done parallely for year 2024 as the model in the 2nd tool call does not have any input about Super Bowl 2024 winner\n",
    "\n",
    "query = \"Who won the super bowl in 2021? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "abot = Agent(llm, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who won the super bowl in 2021? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner of the Super Bowl in 2021 was the Tampa Bay Buccaneers. The Tampa Bay Buccaneers' headquarters is located in the state of Florida. The GDP of Florida is approximately $1.28 trillion.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "question_prompt_template=ChatPromptTemplate.from_template(\"Who won the super bowl in {year}? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = question_prompt_template | RunnableLambda(lambda x: {\"messages\": x.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Who won the super bowl in 2022? In what state is the winning team headquarters located? What is the GDP of that state? Answer each question.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_prompt_template.invoke({\"year\":2022}) | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.ai-agents-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85ade190b7ea06f5c3fae391869563cce7076cc20a1d2ee17f1a0c9eee8d8039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
