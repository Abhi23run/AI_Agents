{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key = os.getenv('GROQ_API_KEY'))\n",
    "# MODEL = 'llama3-70b-8192'\n",
    "MODEL= 'llama-3.3-70b-versatile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=MODEL, \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "average_dog_weight:\n",
    "e.g. average_dog_weight: Collie\n",
    "returns average weight of a dog when given the breed\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: How much does a Bulldog weigh?\n",
    "Thought: I should look the dogs weight using average_dog_weight\n",
    "Action: average_dog_weight: Bulldog\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: A Bulldog weights 51 lbs\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: A bulldog weights 51 lbs\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(what):\n",
    "    return eval(what)\n",
    "\n",
    "def average_dog_weight(name):\n",
    "    if name in \"Scottish Terrier\": \n",
    "        return(\"Scottish Terriers average 20 lbs\")\n",
    "    elif name in \"Border Collie\":\n",
    "        return(\"a Border Collies average weight is 37 lbs\")\n",
    "    elif name in \"Toy Poodle\":\n",
    "        return(\"a toy poodles average weight is 7 lbs\")\n",
    "    else:\n",
    "        return(\"An average dog weights 50 lbs\")\n",
    "\n",
    "known_actions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_dog_weight\": average_dog_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up the dog's weight using average_dog_weight\n",
      "Action: average_dog_weight: Toy Poodle\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = abot(\"How much does a toy poodle weigh?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a toy poodles average weight is 7 lbs'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = average_dog_weight(\"Toy Poodle\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: A toy poodle weighs 7 lbs.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\naverage_dog_weight:\\ne.g. average_dog_weight: Collie\\nreturns average weight of a dog when given the breed\\n\\nExample session:\\n\\nQuestion: How much does a Bulldog weigh?\\nThought: I should look the dogs weight using average_dog_weight\\nAction: average_dog_weight: Bulldog\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: A Bulldog weights 51 lbs\\n\\nYou then output:\\n\\nAnswer: A bulldog weights 51 lbs'},\n",
       " {'role': 'user', 'content': 'How much does a toy poodle weigh?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Thought: I should look up the dog's weight using average_dog_weight\\nAction: average_dog_weight: Toy Poodle\\nPAUSE\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Observation: a toy poodles average weight is 7 lbs'},\n",
       " {'role': 'assistant', 'content': 'Answer: A toy poodle weighs 7 lbs.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all of this in unified function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_re = re.compile('^Action: (\\w+): (.*)$')   # python regular expression to selection action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a) \n",
    "            for a in result.split('\\n') \n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            # There is an action to run\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To find the combined weight of the two dogs, I need to find the average weight of a Border Collie and a Scottish Terrier. I can use the average_dog_weight action to get the weights of each breed and then add them together.\n",
      "\n",
      "Action: average_dog_weight: Border Collie\n",
      "PAUSE\n",
      " -- running average_dog_weight Border Collie\n",
      "Observation: a Border Collies average weight is 37 lbs\n",
      "Thought: Now that I have the average weight of a Border Collie, I need to find the average weight of a Scottish Terrier. I can use the average_dog_weight action again to get the weight of a Scottish Terrier.\n",
      "\n",
      "Action: average_dog_weight: Scottish Terrier\n",
      "PAUSE\n",
      " -- running average_dog_weight Scottish Terrier\n",
      "Observation: Scottish Terriers average 20 lbs\n",
      "Thought: Now that I have the average weights of both breeds, I can add them together to find the combined weight of the two dogs.\n",
      "\n",
      "Action: calculate: 37 + 20\n",
      "PAUSE\n",
      " -- running calculate 37 + 20\n",
      "Observation: 57\n",
      "Thought: The calculation is complete, and I have the combined weight of the two dogs.\n",
      "\n",
      "Answer: The combined weight of the Border Collie and the Scottish Terrier is 57 lbs.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Langgraph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=2) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=MODEL,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
    "abot = Agent(llm, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather today'}, 'id': 'call_ffy0', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in San Francisco is partly cloudy with a temperature of 53.1Â°F (11.7Â°C) and a feels-like temperature of 49.5Â°F (9.7Â°C). The wind is blowing at 11.0 mph (17.6 kph) from the northwest, and the humidity is 86%.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Super Bowl 2021 winner'}, 'id': 'call_0s2t', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Tampa Bay Buccaneers headquarters location'}, 'id': 'call_kqzp', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'GDP of Florida'}, 'id': 'call_avhe', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "# From the results, it looks like all the tool calls were done parallely for year 2024 as the model in the 2nd tool call does not have any input about Super Bowl 2024 winner\n",
    "\n",
    "query = \"Who won the super bowl in 2021? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "abot = Agent(llm, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who won the super bowl in 2021? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner of the Super Bowl in 2021 was the Tampa Bay Buccaneers. The Tampa Bay Buccaneers' headquarters is located in the state of Florida. The GDP of Florida is approximately $1.28 trillion.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "question_prompt_template=ChatPromptTemplate.from_template(\"Who won the {competition} in {year}? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a chain for making the call more programmatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain = question_prompt_template | RunnableLambda(lambda x: {\"messages\": x.messages}) | abot.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'La Liga 2022 winner'}, 'id': 'call_g440', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Real Madrid headquarters location'}, 'id': 'call_d97d', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'GDP of Madrid state'}, 'id': 'call_903k', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "result = graph_chain.invoke({\"year\": 2022, \"competition\": \"La Liga\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner of the La Liga in 2022 was Real Madrid. The headquarters of Real Madrid is located in the state of Madrid. The GDP of the state of Madrid is â‚¬124,780M.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding persistence and streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        # self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.graph=graph\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "llm = ChatGroq(\n",
    "    model=MODEL,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=1\n",
    ")\n",
    "abot = Agent(llm, [tool], system=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5jzt', 'function': {'arguments': '{\"query\": \"San Francisco weather today\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 350, 'total_tokens': 371, 'completion_time': 0.076363636, 'prompt_time': 0.018157823, 'queue_time': 0.19787941, 'total_time': 0.094521459}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_7b42aeb9fa', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c962635a-d635-4b11-b12b-d6f01f0dd0a4-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather today'}, 'id': 'call_5jzt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 350, 'output_tokens': 21, 'total_tokens': 371})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather today'}, 'id': 'call_5jzt', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739826901, \\'localtime\\': \\'2025-02-17 13:15\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739826900, \\'last_updated\\': \\'2025-02-17 13:15\\', \\'temp_c\\': 11.7, \\'temp_f\\': 53.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 11.0, \\'wind_kph\\': 17.6, \\'wind_degree\\': 306, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1021.0, \\'pressure_in\\': 30.16, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 75, \\'feelslike_c\\': 9.7, \\'feelslike_f\\': 49.5, \\'windchill_c\\': 7.7, \\'windchill_f\\': 45.9, \\'heatindex_c\\': 9.1, \\'heatindex_f\\': 48.4, \\'dewpoint_c\\': 8.5, \\'dewpoint_f\\': 47.3, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 3.0, \\'gust_mph\\': 14.9, \\'gust_kph\\': 23.9}}\"}, {\\'url\\': \\'https://www.yahoo.com/news/february-17-2025-san-francisco-132454541.html\\', \\'content\\': \"Published Time: 2025-02-17T13:24:54.000Z February 17, 2025 San Francisco Bay Area weather forecast Search query Search the web News Finance Sports Manage your account Help Add or switch accounts Sign out Search the web Advertisement Advertisement Advertisement Return to homepage How to cut down on screen time KRON San Francisco February 17, 2025 San Francisco Bay Area weather forecast KRON San Francisco Mon, February 17, 2025 at 1:24 PM UTC KRON4 Meteorologist John Shrable has a look at this week\\'s forecast. https://www.kron4.com Solve the daily Crossword 40,667 people played the daily Crossword recently. Can you solve it faster than others?40,667 people played the daily Crossword recently. Can you solve it faster than others? Crossword Play on Yahoo Yahoo! Â© 2025 Yahoo.\"}]', name='tavily_search_results_json', tool_call_id='call_5jzt')]\n",
      "[AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 53.1Â°F (11.7Â°C) and a feels-like temperature of 49.5Â°F (9.7Â°C). The wind is blowing at 11.0 mph (17.6 kph) from the northwest, and the humidity is 86%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 1007, 'total_tokens': 1077, 'completion_time': 0.254545455, 'prompt_time': 0.04266617, 'queue_time': 0.198511771, 'total_time': 0.297211625}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_0a4b7a8df3', 'finish_reason': 'stop', 'logprobs': None}, id='run-279e1ef2-6c89-4443-9c3f-c9bb7b347769-0', usage_metadata={'input_tokens': 1007, 'output_tokens': 70, 'total_tokens': 1077})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "New Message :\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_x9f7', 'function': {'arguments': '{\"query\": \"Los Angeles weather today\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1091, 'total_tokens': 1112, 'completion_time': 0.076363636, 'prompt_time': 0.045823225, 'queue_time': 0.208935456, 'total_time': 0.122186861}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ca0059abb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c8f052f5-9de3-482c-a6af-fbe32eac94d1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Los Angeles weather today'}, 'id': 'call_x9f7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1091, 'output_tokens': 21, 'total_tokens': 1112})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Los Angeles weather today'}, 'id': 'call_x9f7', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.0522, \\'lon\\': -118.2428, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739829868, \\'localtime\\': \\'2025-02-17 14:04\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739829600, \\'last_updated\\': \\'2025-02-17 14:00\\', \\'temp_c\\': 17.8, \\'temp_f\\': 64.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 4.9, \\'wind_kph\\': 7.9, \\'wind_degree\\': 201, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1015.0, \\'pressure_in\\': 29.96, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 63, \\'cloud\\': 0, \\'feelslike_c\\': 17.8, \\'feelslike_f\\': 64.0, \\'windchill_c\\': 19.1, \\'windchill_f\\': 66.3, \\'heatindex_c\\': 19.1, \\'heatindex_f\\': 66.3, \\'dewpoint_c\\': 9.0, \\'dewpoint_f\\': 48.1, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 2.1, \\'gust_mph\\': 5.7, \\'gust_kph\\': 9.1}}\"}, {\\'url\\': \\'https://world-weather.info/forecast/usa/los_angeles/february-2025/\\', \\'content\\': \"Weather in Los Angeles in February 2025 (California) - Detailed Weather Forecast for a Month Weather Weather in Los Angeles Weather in Los Angeles in February 2025 Los Angeles Weather Forecast for February 2025 is based on long term prognosis and previous years\\' statistical data. 1 +64Â°+46Â° 2 +66Â°+52Â° 3 +63Â°+48Â° 4 +61Â°+50Â° 5 +61Â°+52Â° 6 +59Â°+57Â° 7 +59Â°+57Â° 8 +63Â°+50Â° 9 +66Â°+52Â° 10 +61Â°+50Â° 11 +59Â°+52Â° 12 +57Â°+50Â° 13 +57Â°+50Â° 14 +61Â°+50Â° 15 +66Â°+46Â° 16 +68Â°+50Â° 17 +66Â°+50Â° 18 +75Â°+54Â° 19 +73Â°+63Â° 20 +72Â°+64Â° 21 +66Â°+61Â° 22 +63Â°+57Â° +63Â°+52Â° +63Â°+52Â° +63Â°+52Â° +64Â°+54Â° +63Â°+54Â° +64Â°+54Â° Extended weather forecast in Los Angeles Weather in Washington, D.C.+39Â° Sacramento+52Â° Norwalk+57Â° Pasadena+55Â° Rosemead+57Â° Inglewood+57Â° Bellflower+57Â° Burbank+55Â° Compton+57Â° Bandini+57Â° world\\'s temperature today Temperature units\"}]', name='tavily_search_results_json', tool_call_id='call_x9f7')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is sunny with a temperature of 64.0Â°F (17.8Â°C) and a feels-like temperature of 64.0Â°F (17.8Â°C). The wind is blowing at 4.9 mph (7.9 kph) from the south-southwest, and the humidity is 63%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 1897, 'total_tokens': 1969, 'completion_time': 0.261818182, 'prompt_time': 0.08194304, 'queue_time': 0.21824579000000002, 'total_time': 0.343761222}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ca0059abb', 'finish_reason': 'stop', 'logprobs': None}, id='run-8d0ca998-c46b-4b68-bf15-dc7e2e7b3a85-0', usage_metadata={'input_tokens': 1897, 'output_tokens': 72, 'total_tokens': 1969})]}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "New Message :\n",
      "{'messages': [AIMessage(content='Los Angeles is warmer than San Francisco. The current temperature in Los Angeles is 64.0Â°F (17.8Â°C), while the current temperature in San Francisco is 53.1Â°F (11.7Â°C).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 1983, 'total_tokens': 2029, 'completion_time': 0.167272727, 'prompt_time': 0.107738489, 'queue_time': 0.220165905, 'total_time': 0.275011216}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_5f849c5a0b', 'finish_reason': 'stop', 'logprobs': None}, id='run-ae4b6470-79c7-46f4-9c5c-1263c1502d46-0', usage_metadata={'input_tokens': 1983, 'output_tokens': 46, 'total_tokens': 2029})]}\n"
     ]
    }
   ],
   "source": [
    "with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "    app = abot.graph.compile(checkpointer=checkpointer)\n",
    "    for event in app.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v['messages'])\n",
    "    print('-'*100)\n",
    "    print('New Message :')\n",
    "    messages = [HumanMessage(content=\"What about in la?\")]\n",
    "    for event in app.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v) \n",
    "\n",
    "    print('-'*100)\n",
    "    print('New Message :')\n",
    "    messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "    for event in app.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={})]}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0jq7', 'function': {'arguments': '{\"query\": \"San Francisco weather today\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 350, 'total_tokens': 371, 'completion_time': 0.076363636, 'prompt_time': 0.016865078, 'queue_time': 0.23646988500000002, 'total_time': 0.093228714}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_5f849c5a0b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2fb01750-dac0-4494-8c30-fef7e7dfe36c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather today'}, 'id': 'call_0jq7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 350, 'output_tokens': 21, 'total_tokens': 371})]}\n",
      "{'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0jq7', 'function': {'arguments': '{\"query\": \"San Francisco weather today\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 350, 'total_tokens': 371, 'completion_time': 0.076363636, 'prompt_time': 0.016865078, 'queue_time': 0.23646988500000002, 'total_time': 0.093228714}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_5f849c5a0b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2fb01750-dac0-4494-8c30-fef7e7dfe36c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather today'}, 'id': 'call_0jq7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 350, 'output_tokens': 21, 'total_tokens': 371})]}}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather today'}, 'id': 'call_0jq7', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739830324, \\'localtime\\': \\'2025-02-17 14:12\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739829600, \\'last_updated\\': \\'2025-02-17 14:00\\', \\'temp_c\\': 12.2, \\'temp_f\\': 54.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 10.5, \\'wind_kph\\': 16.9, \\'wind_degree\\': 294, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1021.0, \\'pressure_in\\': 30.15, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 83, \\'cloud\\': 75, \\'feelslike_c\\': 10.4, \\'feelslike_f\\': 50.8, \\'windchill_c\\': 8.2, \\'windchill_f\\': 46.7, \\'heatindex_c\\': 9.6, \\'heatindex_f\\': 49.2, \\'dewpoint_c\\': 8.9, \\'dewpoint_f\\': 47.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 2.3, \\'gust_mph\\': 14.4, \\'gust_kph\\': 23.2}}\"}, {\\'url\\': \\'https://www.yahoo.com/news/february-17-2025-san-francisco-132454541.html\\', \\'content\\': \"Published Time: 2025-02-17T13:24:54.000Z February 17, 2025 San Francisco Bay Area weather forecast Search query Search the web News Finance Sports Manage your account Help Add or switch accounts Sign out Search the web Advertisement Advertisement Advertisement Return to homepage How to cut down on screen time KRON San Francisco February 17, 2025 San Francisco Bay Area weather forecast KRON San Francisco Mon, February 17, 2025 at 1:24 PM UTC KRON4 Meteorologist John Shrable has a look at this week\\'s forecast. https://www.kron4.com Solve the daily Crossword 40,667 people played the daily Crossword recently. Can you solve it faster than others?40,667 people played the daily Crossword recently. Can you solve it faster than others? Crossword Play on Yahoo Yahoo! Â© 2025 Yahoo.\"}]', name='tavily_search_results_json', tool_call_id='call_0jq7')]}\n",
      "{'action': {'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739830324, \\'localtime\\': \\'2025-02-17 14:12\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739829600, \\'last_updated\\': \\'2025-02-17 14:00\\', \\'temp_c\\': 12.2, \\'temp_f\\': 54.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 10.5, \\'wind_kph\\': 16.9, \\'wind_degree\\': 294, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1021.0, \\'pressure_in\\': 30.15, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 83, \\'cloud\\': 75, \\'feelslike_c\\': 10.4, \\'feelslike_f\\': 50.8, \\'windchill_c\\': 8.2, \\'windchill_f\\': 46.7, \\'heatindex_c\\': 9.6, \\'heatindex_f\\': 49.2, \\'dewpoint_c\\': 8.9, \\'dewpoint_f\\': 47.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 2.3, \\'gust_mph\\': 14.4, \\'gust_kph\\': 23.2}}\"}, {\\'url\\': \\'https://www.yahoo.com/news/february-17-2025-san-francisco-132454541.html\\', \\'content\\': \"Published Time: 2025-02-17T13:24:54.000Z February 17, 2025 San Francisco Bay Area weather forecast Search query Search the web News Finance Sports Manage your account Help Add or switch accounts Sign out Search the web Advertisement Advertisement Advertisement Return to homepage How to cut down on screen time KRON San Francisco February 17, 2025 San Francisco Bay Area weather forecast KRON San Francisco Mon, February 17, 2025 at 1:24 PM UTC KRON4 Meteorologist John Shrable has a look at this week\\'s forecast. https://www.kron4.com Solve the daily Crossword 40,667 people played the daily Crossword recently. Can you solve it faster than others?40,667 people played the daily Crossword recently. Can you solve it faster than others? Crossword Play on Yahoo Yahoo! Â© 2025 Yahoo.\"}]', name='tavily_search_results_json', tool_call_id='call_0jq7')]}}\n",
      "{'messages': [AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 54.0Â°F (12.2Â°C) and a feels-like temperature of 50.8Â°F (10.4Â°C). The wind is blowing at 10.5 mph (16.9 kph) from the WNW direction, and the humidity is 83%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 1008, 'total_tokens': 1080, 'completion_time': 0.261818182, 'prompt_time': 0.047856102, 'queue_time': 0.23709202699999998, 'total_time': 0.309674284}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ca0059abb', 'finish_reason': 'stop', 'logprobs': None}, id='run-0acf51e0-b7c3-421a-ac17-c076b4829176-0', usage_metadata={'input_tokens': 1008, 'output_tokens': 72, 'total_tokens': 1080})]}\n",
      "{'llm': {'messages': [AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 54.0Â°F (12.2Â°C) and a feels-like temperature of 50.8Â°F (10.4Â°C). The wind is blowing at 10.5 mph (16.9 kph) from the WNW direction, and the humidity is 83%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 1008, 'total_tokens': 1080, 'completion_time': 0.261818182, 'prompt_time': 0.047856102, 'queue_time': 0.23709202699999998, 'total_time': 0.309674284}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ca0059abb', 'finish_reason': 'stop', 'logprobs': None}, id='run-0acf51e0-b7c3-421a-ac17-c076b4829176-0', usage_metadata={'input_tokens': 1008, 'output_tokens': 72, 'total_tokens': 1080})]}}\n"
     ]
    }
   ],
   "source": [
    "abot = Agent(llm, [tool], system=prompt)\n",
    "async with AsyncSqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "    app = abot.graph.compile(checkpointer=checkpointer)\n",
    "    messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "    thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "    async for event in app.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "        kind = event[\"event\"]\n",
    "        if kind == \"on_chain_stream\":\n",
    "            print(event[\"data\"][\"chunk\"])\n",
    "            # content = event[\"data\"][\"chunk\"].content\n",
    "            # if content:\n",
    "            #     print(content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.ai-agents-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85ade190b7ea06f5c3fae391869563cce7076cc20a1d2ee17f1a0c9eee8d8039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
